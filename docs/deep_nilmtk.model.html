

<!DOCTYPE html>
<html class="writer-html5" lang="python" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Model package &mdash; deep_nilmtk 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Preprocessing package" href="deep_nilmtk.preprocessing.html" />
    <link rel="prev" title="Loader package" href="deep_nilmtk.loader.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> deep_nilmtk
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">Deep-NILMtk</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="deep_nilmtk.config.html">Config package</a></li>
<li class="toctree-l2"><a class="reference internal" href="deep_nilmtk.disaggregate.html">Disaggregate package</a></li>
<li class="toctree-l2"><a class="reference internal" href="deep_nilmtk.loader.html">Loader package</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Model package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-deep_nilmtk.model.baselines">baselines module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-deep_nilmtk.model.bert4nilm">bert4nilm module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-deep_nilmtk.model.tempool">tempool module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-deep_nilmtk.model.unet">unet module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-deep_nilmtk.model.wavenet">wavenet module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-deep_nilmtk.model.model_pil">model_pil module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="deep_nilmtk.preprocessing.html">Preprocessing package</a></li>
<li class="toctree-l2"><a class="reference internal" href="deep_nilmtk.utils.html">Utils package</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">deep_nilmtk</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="modules.html">Deep-NILMtk</a> &raquo;</li>
        
      <li>Model package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/deep_nilmtk.model.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-deep_nilmtk.model">
<span id="model-package"></span><h1>Model package<a class="headerlink" href="#module-deep_nilmtk.model" title="Permalink to this headline">¶</a></h1>
<p>This package contain the networks implementation for the models available in Deep-NILMtk as well as 
one generic Lightning model that can work independently of the PyTorch model.</p>
<div class="section" id="module-deep_nilmtk.model.baselines">
<span id="baselines-module"></span><h2>baselines module<a class="headerlink" href="#module-deep_nilmtk.model.baselines" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.DAE">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.baselines.</span></span><span class="sig-name descname"><span class="pre">DAE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#DAE"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.DAE" title="Permalink to this definition">¶</a></dt>
<dd><p>PyTorch implementation of the DAE
NILM model as porposed in :
<a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3360322.3360844">https://dl.acm.org/doi/pdf/10.1145/3360322.3360844</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>params</strong> (<em>dict</em>) -- dictionnary of values relative to hyper-parameters.</p>
</dd>
</dl>
<p>Besides the additional paramter from teh parent model, the params dictionnay is expected to include the following keys:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_type</strong> (<em>int</em>) -- The number of input features, defaults to 1.</p></li>
<li><p><strong>appliances</strong> (<em>list of str</em>) -- A list of appliances.</p></li>
<li><p><strong>pool_filter</strong> (<em>int</em>) -- The size of pooling filter, defaults to 50.</p></li>
<li><p><strong>latent_size</strong> (<em>int</em>) -- The number of nodes in the last layer, defaults to 1024.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.DAE.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#DAE.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.DAE.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.DAE.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.baselines.DAE.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.RNN">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.baselines.</span></span><span class="sig-name descname"><span class="pre">RNN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#RNN"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.RNN" title="Permalink to this definition">¶</a></dt>
<dd><p>PyTorch implementation of the RNN
NILM model as porposed in :
<a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3360322.3360844">https://dl.acm.org/doi/pdf/10.1145/3360322.3360844</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>params</strong> (<em>dict</em>) -- dictionnary of values relative to hyper-parameters.</p>
</dd>
</dl>
<p>Besides the additional paramter from teh parent model, the params dictionnay is expected to include the following keys:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_type</strong> (<em>int</em>) -- The number of input features, defaults to 1.</p></li>
<li><p><strong>appliances</strong> (<em>list of str</em>) -- A list of appliances.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.RNN.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#RNN.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.RNN.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.RNN.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.baselines.RNN.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.S2P">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.baselines.</span></span><span class="sig-name descname"><span class="pre">S2P</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#S2P"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.S2P" title="Permalink to this definition">¶</a></dt>
<dd><p>This class is an abstract class  for Sequence to point models. By implementing this class, 
you can avoid to implement the predict and the forward functions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>params</strong> (<em>dict</em>) -- dictionnary of values relative to hyper-parameters.</p>
</dd>
</dl>
<p>The dictionnay is expected to include the following keys:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_norm</strong> (<em>str.</em>) -- the type of normlization of the target power, defaults to 'z-norm'.</p></li>
<li><p><strong>mean</strong> (<em>float.</em>) -- The mean consumption value of the target appliance, defaults to 0.</p></li>
<li><p><strong>std</strong> (<em>float.</em>) -- The std consumption value  the target power, defaults to 1</p></li>
<li><p><strong>min</strong> (<em>float.</em>) -- The mininum consumption value of the target appliance, defaults to 0.</p></li>
<li><p><strong>max</strong> (<em>float.</em>) -- The maximum consumption value  the target power, defaults to 1</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.S2P.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#S2P.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.S2P.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate prediction during testing for the test_dataLoader</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> -- pre-trained model.</p></li>
<li><p><strong>test_dataloader</strong> (<em>dataLoader</em>) -- data loader for the testing period.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Disaggregated power consumption.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.S2P.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#S2P.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.S2P.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Disaggregates a batch of data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>Tensor</em>) -- A batch of data</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss function as returned form the model and the MAE as returned from the model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple(float, float)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.S2P.suggest_hparams">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">suggest_hparams</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trial</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#S2P.suggest_hparams"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.S2P.suggest_hparams" title="Permalink to this definition">¶</a></dt>
<dd><p>Function returning list of params that will be suggested from optuna</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>trial</strong> (<em>optuna.trial</em>) -- Optuna Trial.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Parameters with values suggested by optuna</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.S2P.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.baselines.S2P.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.S2S">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.baselines.</span></span><span class="sig-name descname"><span class="pre">S2S</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#S2S"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.S2S" title="Permalink to this definition">¶</a></dt>
<dd><p>This class is an abstract class  for Sequence to Sequence models. By implementing this class, 
you can avoid to implement the predict and the forward functions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>params</strong> (<em>dict</em>) -- dictionnary of values relative to hyper-parameters.</p>
</dd>
</dl>
<p>The dictionnay is expected to include the following keys:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_norm</strong> (<em>str.</em>) -- the type of normlization of the target power, defaults to 'z-norm'.</p></li>
<li><p><strong>mean</strong> (<em>float.</em>) -- The mean consumption value of the target appliance, defaults to 0.</p></li>
<li><p><strong>std</strong> (<em>float.</em>) -- The std consumption value  the target power, defaults to 1</p></li>
<li><p><strong>min</strong> (<em>float.</em>) -- The mininum consumption value of the target appliance, defaults to 0.</p></li>
<li><p><strong>max</strong> (<em>float.</em>) -- The maximum consumption value  the target power, defaults to 1</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.S2S.aggregate_seqs">
<span class="sig-name descname"><span class="pre">aggregate_seqs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#S2S.aggregate_seqs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.S2S.aggregate_seqs" title="Permalink to this definition">¶</a></dt>
<dd><p>Aggregate the overleapping sequences using the mean</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prediction</strong> (<em>tensor</em>) -- test predictions of the current model</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Aggregted sequence</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.S2S.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#S2S.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.S2S.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate prediction during testing for the test_dataLoader</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> -- pre-trained model.</p></li>
<li><p><strong>test_dataloader</strong> -- data loader for the testing period.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>data loader for the testing period.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.S2S.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#S2S.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.S2S.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Disaggregates a batch of data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>Tensor</em>) -- A batch of data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss function as returned form the model and MAE as returned from the model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple(float,float)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.S2S.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.baselines.S2S.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.Seq2Point">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.baselines.</span></span><span class="sig-name descname"><span class="pre">Seq2Point</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#Seq2Point"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.Seq2Point" title="Permalink to this definition">¶</a></dt>
<dd><p id="seqpoint">PyTorch implementation of the Seq-to-point
NILM model as porposed in :
<a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3360322.3360844">https://dl.acm.org/doi/pdf/10.1145/3360322.3360844</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>params</strong> (<em>dict</em>) -- dictionnary of values relative to hyper-parameters.</p>
</dd>
</dl>
<p>Besides the additional paramter from teh parent model, the params dictionnay is expected to include the following keys:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_type</strong> (<em>int</em>) -- The number of input features, defaults to 1.</p></li>
<li><p><strong>appliances</strong> (<em>list of str</em>) -- A list of appliances.</p></li>
<li><p><strong>pool_filter</strong> (<em>int</em>) -- The size of pooling filter, defaults to 50.</p></li>
<li><p><strong>latent_size</strong> (<em>int</em>) -- The number of nodes in the last layer, defaults to 1024.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.Seq2Point.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#Seq2Point.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.Seq2Point.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.Seq2Point.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.baselines.Seq2Point.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.Seq2Seq">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.baselines.</span></span><span class="sig-name descname"><span class="pre">Seq2Seq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#Seq2Seq"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.Seq2Seq" title="Permalink to this definition">¶</a></dt>
<dd><p id="seqseq">PyTorch implementation of the Window-GRU
NILM model as porposed in :
<a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3360322.3360844">https://dl.acm.org/doi/pdf/10.1145/3360322.3360844</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>params</strong> (<em>dict</em>) -- dictionnary of values relative to hyper-parameters.</p>
</dd>
</dl>
<p>Besides the additional paramter from teh parent model, the params dictionnay is expected to include the following keys:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_type</strong> (<em>int</em>) -- The number of input features, defaults to 1.</p></li>
<li><p><strong>appliances</strong> (<em>list of str</em>) -- A list of appliances.</p></li>
<li><p><strong>pool_filter</strong> (<em>int</em>) -- The size of pooling filter, defaults to 50.</p></li>
<li><p><strong>latent_size</strong> (<em>int</em>) -- The number of nodes in the last layer, defaults to 1024.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.Seq2Seq.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#Seq2Seq.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.Seq2Seq.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.Seq2Seq.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.baselines.Seq2Seq.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.WindowGRU">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.baselines.</span></span><span class="sig-name descname"><span class="pre">WindowGRU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#WindowGRU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.WindowGRU" title="Permalink to this definition">¶</a></dt>
<dd><p>PyTorch implementation of the Window-GRU
NILM model as porposed in :
<a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3360322.3360844">https://dl.acm.org/doi/pdf/10.1145/3360322.3360844</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>params</strong> (<em>dict</em>) -- dictionnary of values relative to hyper-parameters.</p>
</dd>
</dl>
<p>Besides the additional paramter from teh parent model, the params dictionnay is expected to include the following keys:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_type</strong> (<em>int</em>) -- The number of input features, defaults to 1.</p></li>
<li><p><strong>appliances</strong> (<em>list of str</em>) -- A list of appliances.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.WindowGRU.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/baselines.html#WindowGRU.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.baselines.WindowGRU.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.baselines.WindowGRU.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.baselines.WindowGRU.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deep_nilmtk.model.bert4nilm">
<span id="bert4nilm-module"></span><h2>bert4nilm module<a class="headerlink" href="#module-deep_nilmtk.model.bert4nilm" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.Attention">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">Attention</span></span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#Attention"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.Attention" title="Permalink to this definition">¶</a></dt>
<dd><p>Attention layer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> (<em>tensor</em>) -- Query values</p></li>
<li><p><strong>key</strong> (<em>tensor</em>) -- Key values</p></li>
<li><p><strong>value</strong> (<em>tensor</em>) -- Values</p></li>
<li><p><strong>mask</strong> (<em>tensor</em><em>, </em><em>optional</em>) -- Mask for a causal model, defaults to None</p></li>
<li><p><strong>dropout</strong> (<em>float</em><em>, </em><em>optional</em>) -- Dropout, defaults to None</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output of the attention layer and attention score</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple(tensor, tensor)</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.Attention.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#Attention.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.Attention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.Attention.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.Attention.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.BERT4NILM">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">BERT4NILM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#BERT4NILM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.BERT4NILM" title="Permalink to this definition">¶</a></dt>
<dd><p id="bert">BERT4NILM implementation. 
Original paper can be found here: <a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3427771.3429390">https://dl.acm.org/doi/pdf/10.1145/3427771.3429390</a>
Original code can be found here: <a class="reference external" href="https://github.com/Yueeeeeeee/BERT4NILM">https://github.com/Yueeeeeeee/BERT4NILM</a></p>
<p>The hyperparameter dictionnary is expected to include the following parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>threshold</strong> (<em>List of floats</em>) -- The threshold for states generation in the target power consumption, defaults to None</p></li>
<li><p><strong>cutoff</strong> (<em>List of floats</em>) -- The cutoff for states generation in the target power consumption, defaults to None</p></li>
<li><p><strong>min_on</strong> (<em>List of floats</em>) -- The min on duration for states generation in the target power consumption, defaults to None</p></li>
<li><p><strong>min_off</strong> (<em>List of floats</em>) -- The min off duration for states generation in the target power consumption, defaults to None</p></li>
<li><p><strong>in_size</strong> (<em>int</em>) -- The length of the input sequence, defaults to 488.</p></li>
<li><p><strong>stride</strong> (<em>int</em>) -- The distance between two consecutive sequences, defaults to 1.</p></li>
<li><p><strong>hidden</strong> (<em>int</em>) -- The hidden size, defaults to 256</p></li>
<li><p><strong>heads</strong> (<em>int</em>) -- The number of attention heads in each transformer block, defaults to 2</p></li>
<li><p><strong>n_layers</strong> (<em>int</em>) -- the number of transformer blocks in the model, defaults to 2</p></li>
</ul>
</dd>
<dt class="field-even">Params dropout</dt>
<dd class="field-even"><p>The dropout, defaults to 0.2</p>
</dd>
</dl>
<p>it can be used as follow:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="s1">&#39;Bert4NILM&#39;</span><span class="p">:</span> <span class="n">NILMExperiment</span><span class="p">({</span>
          <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="s1">&#39;BERT4NILM&#39;</span><span class="p">,</span> 
          <span class="s1">&#39;in_size&#39;</span><span class="p">:</span> <span class="mi">480</span><span class="p">,</span> 
          <span class="s1">&#39;feature_type&#39;</span><span class="p">:</span><span class="s1">&#39;main&#39;</span><span class="p">,</span>
          <span class="s1">&#39;stride&#39;</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span>
          <span class="s1">&#39;max_nb_epochs&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span>
          <span class="s1">&#39;cutoff&#39;</span><span class="p">:{</span>
              <span class="s1">&#39;aggregate&#39;</span><span class="p">:</span> <span class="mi">6000</span><span class="p">,</span>
              <span class="s1">&#39;kettle&#39;</span><span class="p">:</span> <span class="mi">3100</span><span class="p">,</span>
              <span class="s1">&#39;fridge&#39;</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
              <span class="s1">&#39;washing machine&#39;</span><span class="p">:</span> <span class="mi">2500</span><span class="p">,</span>
              <span class="s1">&#39;microwave&#39;</span><span class="p">:</span> <span class="mi">3000</span><span class="p">,</span>
              <span class="s1">&#39;dishwasher&#39;</span><span class="p">:</span> <span class="mi">2500</span>
          <span class="p">},</span>
          <span class="s1">&#39;threshold&#39;</span><span class="p">:{</span>
             <span class="s1">&#39;kettle&#39;</span><span class="p">:</span> <span class="mi">2000</span><span class="p">,</span>
             <span class="s1">&#39;fridge&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
             <span class="s1">&#39;washing machine&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
             <span class="s1">&#39;microwave&#39;</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
             <span class="s1">&#39;dishwasher&#39;</span><span class="p">:</span> <span class="mi">10</span>
          <span class="p">},</span>
          <span class="s1">&#39;min_on&#39;</span><span class="p">:{</span>
            <span class="s1">&#39;kettle&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
            <span class="s1">&#39;fridge&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
            <span class="s1">&#39;washing machine&#39;</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
            <span class="s1">&#39;microwave&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
            <span class="s1">&#39;dishwasher&#39;</span><span class="p">:</span> <span class="mi">300</span>
          <span class="p">},</span>
          <span class="s1">&#39;min_off&#39;</span><span class="p">:{</span>
              <span class="s1">&#39;kettle&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
              <span class="s1">&#39;fridge&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
              <span class="s1">&#39;washing machine&#39;</span><span class="p">:</span> <span class="mi">26</span><span class="p">,</span>
              <span class="s1">&#39;microwave&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
              <span class="s1">&#39;dishwasher&#39;</span><span class="p">:</span> <span class="mi">300</span>
          <span class="p">},</span>
        <span class="p">})</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.BERT4NILM.aggregate_seqs">
<span class="sig-name descname"><span class="pre">aggregate_seqs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#BERT4NILM.aggregate_seqs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.BERT4NILM.aggregate_seqs" title="Permalink to this definition">¶</a></dt>
<dd><p>Aggregate the overleapping sequences using the mean
taking into consideration the stride size</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prediction</strong> (<em>tensor</em>) -- test predictions of the current model</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Aggregted sequence</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.BERT4NILM.compute_status">
<span class="sig-name descname"><span class="pre">compute_status</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#BERT4NILM.compute_status"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.BERT4NILM.compute_status" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates teh states for the  target data based on the threshold</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<em>tensor</em>) -- The target data</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The operational states</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.BERT4NILM.cutoff_energy">
<span class="sig-name descname"><span class="pre">cutoff_energy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#BERT4NILM.cutoff_energy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.BERT4NILM.cutoff_energy" title="Permalink to this definition">¶</a></dt>
<dd><p>Removes the spikes from the data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<em>tesnor</em>) -- Power consumption</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Updated ower consumption</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.BERT4NILM.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sequence</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#BERT4NILM.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.BERT4NILM.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.BERT4NILM.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#BERT4NILM.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.BERT4NILM.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for the test data loader</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>nn.Module</em>) -- Pre-trained model</p></li>
<li><p><strong>test_dataloader</strong> (<em>dataLoader</em>) -- The test data</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Generated predictions</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.BERT4NILM.set_hpramas">
<span class="sig-name descname"><span class="pre">set_hpramas</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cutoff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_on</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_off</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#BERT4NILM.set_hpramas"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.BERT4NILM.set_hpramas" title="Permalink to this definition">¶</a></dt>
<dd><p>Setter for the hyper-parameters related to appliance state generation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cutoff</strong> (<em>float</em>) -- The power cutoff</p></li>
<li><p><strong>threshold</strong> (<em>float</em>) -- Threshold of target power consumption</p></li>
<li><p><strong>min_on</strong> (<em>float</em>) -- Minimum on duration</p></li>
<li><p><strong>min_off</strong> (<em>float</em>) -- Minimum off duration</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.BERT4NILM.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seq_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#BERT4NILM.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.BERT4NILM.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Disaggregates a batch of data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>Tensor</em>) -- A batch of data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss function as returned form the model and MAE as returned from the model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple(float,float)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.BERT4NILM.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.BERT4NILM.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.GELU">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">GELU</span></span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#GELU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.GELU" title="Permalink to this definition">¶</a></dt>
<dd><p>Gaussian Error Linear Units GLU</p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.GELU.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#GELU.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.GELU.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.GELU.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.GELU.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.LayerNorm">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">LayerNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#LayerNorm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.LayerNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalization layer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>features</strong> (<em>int</em>) -- The number of input features</p></li>
<li><p><strong>eps</strong> (<em>float</em><em>, </em><em>optional</em>) -- Regularization factor, defaults to 1e-6</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.LayerNorm.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#LayerNorm.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.LayerNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.LayerNorm.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.LayerNorm.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.MultiHeadedAttention">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">MultiHeadedAttention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#MultiHeadedAttention"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.MultiHeadedAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Multi headed attention layer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>h</strong> (<em>int</em>) -- The number of heads</p></li>
<li><p><strong>d_model</strong> (<em>int</em>) -- The dimension of the model</p></li>
<li><p><strong>dropout</strong> (<em>float</em><em>, </em><em>optional</em>) -- Dropout, defaults to 0.1</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.MultiHeadedAttention.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#MultiHeadedAttention.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.MultiHeadedAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.MultiHeadedAttention.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.MultiHeadedAttention.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.PositionalEmbedding">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">PositionalEmbedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#PositionalEmbedding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.PositionalEmbedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Positional Embedding</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_len</strong> (<em>int</em>) -- maximum length of the input</p></li>
<li><p><strong>d_model</strong> (<em>int</em>) -- dimension of the model</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.PositionalEmbedding.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#PositionalEmbedding.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.PositionalEmbedding.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.PositionalEmbedding.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.PositionalEmbedding.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.PositionwiseFeedForward">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">PositionwiseFeedForward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_ff</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#PositionwiseFeedForward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.PositionwiseFeedForward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the position wise feed forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> (<em>int</em>) -- The dimension of the model</p></li>
<li><p><strong>d_ff</strong> (<em>int</em>) -- size of hidden layer</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.PositionwiseFeedForward.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#PositionwiseFeedForward.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.PositionwiseFeedForward.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.PositionwiseFeedForward.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.PositionwiseFeedForward.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.SublayerConnection">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">SublayerConnection</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#SublayerConnection"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.SublayerConnection" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the addition and layer normalisation
More details can be found <a class="reference external" href="https://arxiv.org/pdf/1706.03762.pdf">https://arxiv.org/pdf/1706.03762.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<em>int</em>) -- the size of teh input</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) -- Dropout</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.SublayerConnection.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sublayer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#SublayerConnection.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.SublayerConnection.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.SublayerConnection.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.SublayerConnection.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.TransformerBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">TransformerBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feed_forward_hidden</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#TransformerBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.TransformerBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Tranformer decoder block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden</strong> (<em>int</em>) -- Dimension of the model</p></li>
<li><p><strong>attn_heads</strong> (<em>int</em>) -- The number of attention heads</p></li>
<li><p><strong>feed_forward_hidden</strong> (<em>int</em>) -- The hidden size of feedforward layer</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) -- Dropout</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.TransformerBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/bert4nilm.html#TransformerBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.TransformerBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.bert4nilm.TransformerBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.bert4nilm.TransformerBlock.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deep_nilmtk.model.tempool">
<span id="tempool-module"></span><h2>tempool module<a class="headerlink" href="#module-deep_nilmtk.model.tempool" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.tempool.Decoder">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.tempool.</span></span><span class="sig-name descname"><span class="pre">Decoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/tempool.html#Decoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.tempool.Decoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Decoder block of the Temporal_pooling layer</p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.tempool.Decoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/tempool.html#Decoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.tempool.Decoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.tempool.Decoder.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.tempool.Decoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.tempool.Encoder">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.tempool.</span></span><span class="sig-name descname"><span class="pre">Encoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/tempool.html#Encoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.tempool.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Decoder block of the Temporal_pooling layer</p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.tempool.Encoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/tempool.html#Encoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.tempool.Encoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.tempool.Encoder.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.tempool.Encoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.tempool.PTPNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.tempool.</span></span><span class="sig-name descname"><span class="pre">PTPNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/tempool.html#PTPNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.tempool.PTPNet" title="Permalink to this definition">¶</a></dt>
<dd><p id="ptp">Source: <a class="reference external" href="https://github.com/lmssdd/TPNILM">https://github.com/lmssdd/TPNILM</a>
Check the paper
Non-Intrusive Load Disaggregation by Convolutional
Neural Network and Multilabel Classification
by Luca Massidda, Marino Marrocu and Simone Manca</p>
<p>The hyperparameter dictionnary is expected to include the following parameters</p>
<p>The hyperparameter dictionnary is expected to include the following parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_size</strong> (<em>int</em>) -- The input sequence length, defaults to 99</p></li>
<li><p><strong>border</strong> (<em>int</em>) -- The delay between the input and out sequence, defaults to 30.</p></li>
<li><p><strong>appliances</strong> (<em>list</em>) -- List of appliances</p></li>
<li><p><strong>feature_type</strong> (<em>str</em>) -- The type of input features generated during pre-processing, defaults to 'main'.</p></li>
<li><p><strong>init_features</strong> -- The number of features in the first encoder layer, defaults to 32.</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) -- Dropout</p></li>
<li><p><strong>target_norm</strong> (<em>str</em>) -- The type of normalization of the target data, defeaults to 'z-norm'.</p></li>
<li><p><strong>mean</strong> (<em>float</em>) -- The mean consumption of the target power, defaults to 0</p></li>
<li><p><strong>std</strong> (<em>float</em>) -- The STD consumption of the target power, defaults to 1</p></li>
</ul>
</dd>
</dl>
<p>It can be used as follows:</p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.tempool.PTPNet.aggregate_seqs">
<span class="sig-name descname"><span class="pre">aggregate_seqs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">states</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/tempool.html#PTPNet.aggregate_seqs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.tempool.PTPNet.aggregate_seqs" title="Permalink to this definition">¶</a></dt>
<dd><p>Aggregates the overleapping sequences using the mean</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prediction</strong> (<em>tensor</em>) -- test predictions of the current model with shape (n_samples + window_size -1 ,window_size)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Aggregted sequence</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.tempool.PTPNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/tempool.html#PTPNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.tempool.PTPNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.tempool.PTPNet.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/tempool.html#PTPNet.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.tempool.PTPNet.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for the test data loader</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>nn.Module</em>) -- Pre-trained model</p></li>
<li><p><strong>test_dataloader</strong> (<em>dataLoader</em>) -- The test data</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Generated predictions</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.tempool.PTPNet.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequence_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/tempool.html#PTPNet.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.tempool.PTPNet.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Disaggregates a batch of data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>Tensor</em>) -- A batch of data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss function as returned form the model and MAE as returned from the model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple(float,float)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.tempool.PTPNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.tempool.PTPNet.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.tempool.TemporalPooling">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.tempool.</span></span><span class="sig-name descname"><span class="pre">TemporalPooling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/tempool.html#TemporalPooling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.tempool.TemporalPooling" title="Permalink to this definition">¶</a></dt>
<dd><p>Temporal Pooling mechanism that combines data with different scales.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.tempool.TemporalPooling.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/tempool.html#TemporalPooling.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.tempool.TemporalPooling.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.tempool.TemporalPooling.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.tempool.TemporalPooling.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deep_nilmtk.model.unet">
<span id="unet-module"></span><h2>unet module<a class="headerlink" href="#module-deep_nilmtk.model.unet" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.unet.UNETNILM">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.unet.</span></span><span class="sig-name descname"><span class="pre">UNETNILM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/unet.html#UNETNILM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.unet.UNETNILM" title="Permalink to this definition">¶</a></dt>
<dd><p id="unet">UNET-NILM impelementation 
The orginal paper can be found here: <a class="reference external" href="https://dl.acm.org/doi/abs/10.1145/3427771.3427859">https://dl.acm.org/doi/abs/10.1145/3427771.3427859</a></p>
<p>The hyperparameter dictionnary is expected to include the following parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>appliances</strong> (<em>list</em>) -- List of appliances, defaults to 1</p></li>
<li><p><strong>feature_type</strong> (<em>str</em>) -- The type of input features generated in the pre-processing, defaults  to 'main'</p></li>
<li><p><strong>n_channels</strong> (<em>int</em>) -- the number of output channels, defaults to 1</p></li>
<li><p><strong>pool_filter</strong> (<em>int</em>) -- Pooling filter, defaults to 8</p></li>
<li><p><strong>latent_size</strong> (<em>int</em>) -- The latent size, defaults to 1024</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.unet.UNETNILM.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/unet.html#UNETNILM.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.unet.UNETNILM.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.unet.UNETNILM.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/unet.html#UNETNILM.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.unet.UNETNILM.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate prediction during testing for the test_dataLoader</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> -- pre-trained model.</p></li>
<li><p><strong>test_dataloader</strong> (<em>dataLoader</em>) -- data loader for the testing period.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Disaggregated power consumption.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.unet.UNETNILM.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/unet.html#UNETNILM.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.unet.UNETNILM.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Disaggregates a batch of data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>Tensor</em>) -- A batch of data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss function as returned form the model and MAE as returned from the model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple(float,float)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.unet.UNETNILM.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.unet.UNETNILM.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.unet.UNETNILMSeq2Quantile">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.unet.</span></span><span class="sig-name descname"><span class="pre">UNETNILMSeq2Quantile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/unet.html#UNETNILMSeq2Quantile"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.unet.UNETNILMSeq2Quantile" title="Permalink to this definition">¶</a></dt>
<dd><p>UNET-NILM impelementation with quantile regression
The orginal paper can be found here: <a class="reference external" href="https://dl.acm.org/doi/abs/10.1145/3427771.3427859">https://dl.acm.org/doi/abs/10.1145/3427771.3427859</a></p>
<p>The hyperparameter dictionnary is expected to include the following parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>appliances</strong> (<em>list</em>) -- List of appliances, defaults to 1</p></li>
<li><p><strong>feature_type</strong> (<em>str</em>) -- The type of input features generated in the pre-processing, defaults  to 'main'</p></li>
<li><p><strong>n_channels</strong> (<em>int</em>) -- the number of output channels, defaults to 1</p></li>
<li><p><strong>pool_filter</strong> (<em>int</em>) -- Pooling filter, defaults to 8</p></li>
<li><p><strong>latent_size</strong> (<em>int</em>) -- The latent size, defaults to 1024</p></li>
<li><p><strong>quantile</strong> -- The quantiles to use during prediction, defaults to [0.1, 0.25, 0.5, 0.75, 0.9]</p></li>
<li><p><strong>quantile</strong> -- list</p></li>
</ul>
</dd>
</dl>
<p>It can be used as follows:</p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.unet.UNETNILMSeq2Quantile.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/unet.html#UNETNILMSeq2Quantile.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.unet.UNETNILMSeq2Quantile.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.unet.UNETNILMSeq2Quantile.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/unet.html#UNETNILMSeq2Quantile.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.unet.UNETNILMSeq2Quantile.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate prediction during testing for the test_dataLoader</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> -- pre-trained model.</p></li>
<li><p><strong>test_dataloader</strong> (<em>dataLoader</em>) -- data loader for the testing period.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Disaggregated power consumption.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.unet.UNETNILMSeq2Quantile.smooth_pinball_loss">
<span class="sig-name descname"><span class="pre">smooth_pinball_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kappa</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/unet.html#UNETNILMSeq2Quantile.smooth_pinball_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.unet.UNETNILMSeq2Quantile.smooth_pinball_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>The implementation of the Pinball loss for NILM, original code can be found in :
<a class="reference external" href="https://github.com/hatalis/smooth-pinball-neural-network/blob/master/pinball_loss.py">https://github.com/hatalis/smooth-pinball-neural-network/blob/master/pinball_loss.py</a>
Hatalis, Kostas, et al. &quot;A Novel Smoothed Loss and Penalty Function 
for Noncrossing Composite Quantile Estimation via Deep Neural Networks.&quot; arXiv preprint (2019).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.unet.UNETNILMSeq2Quantile.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/unet.html#UNETNILMSeq2Quantile.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.unet.UNETNILMSeq2Quantile.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Disaggregates a batch of data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>Tensor</em>) -- A batch of data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss function as returned form the model and MAE as returned from the model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple(float,float)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.unet.UNETNILMSeq2Quantile.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.unet.UNETNILMSeq2Quantile.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deep_nilmtk.model.wavenet">
<span id="wavenet-module"></span><h2>wavenet module<a class="headerlink" href="#module-deep_nilmtk.model.wavenet" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.CNN3">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.wavenet.</span></span><span class="sig-name descname"><span class="pre">CNN3</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seq_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">41</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_binary</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#CNN3"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.CNN3" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.CNN3.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#CNN3.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.CNN3.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.CNN3.init_weights">
<span class="sig-name descname"><span class="pre">init_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#CNN3.init_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.CNN3.init_weights" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.CNN3.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.wavenet.CNN3.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.CNN5">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.wavenet.</span></span><span class="sig-name descname"><span class="pre">CNN5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seq_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">15</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_binary</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#CNN5"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.CNN5" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.CNN5.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#CNN5.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.CNN5.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.CNN5.init_weights">
<span class="sig-name descname"><span class="pre">init_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#CNN5.init_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.CNN5.init_weights" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.CNN5.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.wavenet.CNN5.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.CNN7">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.wavenet.</span></span><span class="sig-name descname"><span class="pre">CNN7</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seq_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">253</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_binary</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#CNN7"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.CNN7" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.CNN7.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#CNN7.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.CNN7.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.CNN7.init_weights">
<span class="sig-name descname"><span class="pre">init_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#CNN7.init_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.CNN7.init_weights" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.CNN7.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.wavenet.CNN7.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.DilatedResidualBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.wavenet.</span></span><span class="sig-name descname"><span class="pre">DilatedResidualBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">residual_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#DilatedResidualBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.DilatedResidualBlock" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.DilatedResidualBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_in</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#DilatedResidualBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.DilatedResidualBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.DilatedResidualBlock.init_weights">
<span class="sig-name descname"><span class="pre">init_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#DilatedResidualBlock.init_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.DilatedResidualBlock.init_weights" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.DilatedResidualBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.wavenet.DilatedResidualBlock.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.DilatedResidualBlock2">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.wavenet.</span></span><span class="sig-name descname"><span class="pre">DilatedResidualBlock2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">residual_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#DilatedResidualBlock2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.DilatedResidualBlock2" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.DilatedResidualBlock2.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_in</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#DilatedResidualBlock2.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.DilatedResidualBlock2.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.DilatedResidualBlock2.init_weights">
<span class="sig-name descname"><span class="pre">init_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#DilatedResidualBlock2.init_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.DilatedResidualBlock2.init_weights" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.DilatedResidualBlock2.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.wavenet.DilatedResidualBlock2.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.WaveNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.wavenet.</span></span><span class="sig-name descname"><span class="pre">WaveNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#WaveNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.WaveNet" title="Permalink to this definition">¶</a></dt>
<dd><p id="wavenilm">WaveNet model for load disaggregtion using residual and dilated convolutions.
This model a sequence to subsequence model where:
Output_sequence_length = Input_sequence_length - L
L = (2 ** layers - 1) * (kernel_size - 1) + 1</p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.WaveNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_in</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#WaveNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.WaveNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.WaveNet.init_weights">
<span class="sig-name descname"><span class="pre">init_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#WaveNet.init_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.WaveNet.init_weights" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.WaveNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.wavenet.WaveNet.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.WaveNetBGRU">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.wavenet.</span></span><span class="sig-name descname"><span class="pre">WaveNetBGRU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">residual_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#WaveNetBGRU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.WaveNetBGRU" title="Permalink to this definition">¶</a></dt>
<dd><p>WaveNet model with a GRU</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>nn</strong> (<em>[</em><em>type</em><em>]</em>) -- [description]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[description]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>[type]</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.WaveNetBGRU.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_in</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#WaveNetBGRU.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.WaveNetBGRU.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.WaveNetBGRU.init_weights">
<span class="sig-name descname"><span class="pre">init_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#WaveNetBGRU.init_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.WaveNetBGRU.init_weights" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.WaveNetBGRU.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.wavenet.WaveNetBGRU.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.WaveNetBGRU_speedup">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.wavenet.</span></span><span class="sig-name descname"><span class="pre">WaveNetBGRU_speedup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">residual_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#WaveNetBGRU_speedup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.WaveNetBGRU_speedup" title="Permalink to this definition">¶</a></dt>
<dd><p>WaveNet with a GRU and faster generation fo predictions</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>nn</strong> (<em>[</em><em>type</em><em>]</em>) -- [description]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[description]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>[type]</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.WaveNetBGRU_speedup.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_in</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#WaveNetBGRU_speedup.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.WaveNetBGRU_speedup.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.WaveNetBGRU_speedup.init_weights">
<span class="sig-name descname"><span class="pre">init_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#WaveNetBGRU_speedup.init_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.WaveNetBGRU_speedup.init_weights" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.WaveNetBGRU_speedup.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.wavenet.WaveNetBGRU_speedup.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.init_bn">
<span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.wavenet.</span></span><span class="sig-name descname"><span class="pre">init_bn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bn</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#init_bn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.init_bn" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize a Batchnorm layer.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.init_layer">
<span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.wavenet.</span></span><span class="sig-name descname"><span class="pre">init_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#init_layer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.init_layer" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize a Linear or Convolutional layer.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deep_nilmtk.model.wavenet.init_layer_2">
<span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.wavenet.</span></span><span class="sig-name descname"><span class="pre">init_layer_2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/wavenet.html#init_layer_2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.wavenet.init_layer_2" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize a Linear or Convolutional layer.</p>
</dd></dl>

</div>
<div class="section" id="module-deep_nilmtk.model.model_pil">
<span id="model-pil-module"></span><h2>model_pil module<a class="headerlink" href="#module-deep_nilmtk.model.model_pil" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.model.model_pil.pilModel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.model.model_pil.</span></span><span class="sig-name descname"><span class="pre">pilModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">net</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hparams</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/model_pil.html#pilModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.model_pil.pilModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Lightning module that is compatible 
with PyTorch models included in Deep-NILMtk.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.model_pil.pilModel.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/model_pil.html#pilModel.configure_optimizers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.model_pil.pilModel.configure_optimizers" title="Permalink to this definition">¶</a></dt>
<dd><p>Choose what optimizers and learning-rate schedulers to use in your optimization.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>two lists: a list of optimzer and a list of scheduler</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.model_pil.pilModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/model_pil.html#pilModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.model_pil.pilModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.forward()</span></code>.</p>
<dl class="simple">
<dt>Args:</dt><dd><p><a href="#id1"><span class="problematic" id="id2">*</span></a>args: Whatever you decide to pass into the forward method.
<a href="#id3"><span class="problematic" id="id4">**</span></a>kwargs: Keyword arguments are also possible.</p>
</dd>
<dt>Return:</dt><dd><p>Your model's output</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.model.model_pil.pilModel.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.model.model_pil.pilModel.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.model_pil.pilModel.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/model_pil.html#pilModel.training_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.model_pil.pilModel.training_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Here you compute and return the training loss and some additional metrics for e.g.
the progress bar or logger.</p>
<dl>
<dt>Args:</dt><dd><dl class="simple">
<dt>batch (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> | (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, ...) | [<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, ...]):</dt><dd><p>The output of your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>. A tensor, tuple or list.</p>
</dd>
</dl>
<p>batch_idx (int): Integer displaying index of this batch
optimizer_idx (int): When using multiple optimizers, this argument will also be present.
hiddens(<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>): Passed in if</p>
<blockquote>
<div><p><a href="#id5"><span class="problematic" id="id6">:paramref:`~pytorch_lightning.core.lightning.LightningModule.truncated_bptt_steps`</span></a> &gt; 0.</p>
</div></blockquote>
</dd>
<dt>Return:</dt><dd><p>Any of.</p>
<ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> - The loss tensor</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dict</span></code> - A dictionary. Can include any keys, but must include the key <code class="docutils literal notranslate"><span class="pre">'loss'</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - Training will skip to the next batch</p></li>
</ul>
</dd>
<dt>Note:</dt><dd><p>Returning <code class="docutils literal notranslate"><span class="pre">None</span></code> is currently not supported for multi-GPU or TPU, or with 16-bit precision enabled.</p>
</dd>
</dl>
<p>In this step you'd normally do the forward pass and calculate the loss for a batch.
You can also do fancier things like multiple forward passes or something model specific.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
<p>If you define multiple optimizers, this step will be called with an additional
<code class="docutils literal notranslate"><span class="pre">optimizer_idx</span></code> parameter.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Multiple optimizers (e.g.: GANs)</span>
<span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer_idx</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">optimizer_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># do training_step with encoder</span>
        <span class="o">...</span>
    <span class="k">if</span> <span class="n">optimizer_idx</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># do training_step with decoder</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>If you add truncated back propagation through time you will also get an additional
argument with the hidden states of the previous step.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Truncated back-propagation through time</span>
<span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">hiddens</span><span class="p">):</span>
    <span class="c1"># hiddens are the hidden states from the previous truncated backprop step</span>
    <span class="o">...</span>
    <span class="n">out</span><span class="p">,</span> <span class="n">hiddens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">hiddens</span><span class="p">)</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s2">&quot;hiddens&quot;</span><span class="p">:</span> <span class="n">hiddens</span><span class="p">}</span>
</pre></div>
</div>
<dl class="simple">
<dt>Note:</dt><dd><p>The loss value shown in the progress bar is smoothed (averaged) over the last values,
so it differs from the actual loss returned in train/validation step.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.model.model_pil.pilModel.validation_step">
<span class="sig-name descname"><span class="pre">validation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deep_nilmtk/model/model_pil.html#pilModel.validation_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deep_nilmtk.model.model_pil.pilModel.validation_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Operates on a single batch of data from the validation set.
In this step you'd might generate examples or calculate anything of interest like accuracy.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># the pseudocode for these calls</span>
<span class="n">val_outs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">val_batch</span> <span class="ow">in</span> <span class="n">val_data</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">validation_step</span><span class="p">(</span><span class="n">val_batch</span><span class="p">)</span>
    <span class="n">val_outs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="n">validation_epoch_end</span><span class="p">(</span><span class="n">val_outs</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>Args:</dt><dd><dl class="simple">
<dt>batch (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> | (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, ...) | [<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, ...]):</dt><dd><p>The output of your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>. A tensor, tuple or list.</p>
</dd>
</dl>
<p>batch_idx (int): The index of this batch
dataloader_idx (int): The index of the dataloader that produced this batch</p>
<blockquote>
<div><p>(only if multiple val dataloaders used)</p>
</div></blockquote>
</dd>
<dt>Return:</dt><dd><ul class="simple">
<li><p>Any object or value</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - Validation will skip to the next batch</p></li>
</ul>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pseudocode of order</span>
<span class="n">val_outs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">val_batch</span> <span class="ow">in</span> <span class="n">val_data</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">validation_step</span><span class="p">(</span><span class="n">val_batch</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">defined</span><span class="p">(</span><span class="s2">&quot;validation_step_end&quot;</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">validation_step_end</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">val_outs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="n">val_outs</span> <span class="o">=</span> <span class="n">validation_epoch_end</span><span class="p">(</span><span class="n">val_outs</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if you have one val dataloader:</span>
<span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="o">...</span>


<span class="c1"># if you have multiple val dataloaders:</span>
<span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 1: A single validation dataset</span>
<span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="c1"># implement your own</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># log 6 example images</span>
    <span class="c1"># or generated text... or whatever</span>
    <span class="n">sample_imgs</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">sample_imgs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">&#39;example_images&#39;</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># calculate acc</span>
    <span class="n">labels_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">labels_hat</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># log the outputs!</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;val_acc&#39;</span><span class="p">:</span> <span class="n">val_acc</span><span class="p">})</span>
</pre></div>
</div>
<p>If you pass in multiple val dataloaders, <a class="reference internal" href="#deep_nilmtk.model.model_pil.pilModel.validation_step" title="deep_nilmtk.model.model_pil.pilModel.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a> will have an additional argument.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 2: multiple validation dataloaders</span>
<span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="c1"># dataloader_idx tells you which dataset this is.</span>
    <span class="o">...</span>
</pre></div>
</div>
<dl class="simple">
<dt>Note:</dt><dd><p>If you don't need to validate you don't need to implement this method.</p>
</dd>
<dt>Note:</dt><dd><p>When the <a class="reference internal" href="#deep_nilmtk.model.model_pil.pilModel.validation_step" title="deep_nilmtk.model.model_pil.pilModel.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a> is called, the model has been put in eval mode
and PyTorch gradients have been disabled. At the end of validation,
the model goes back to training mode and gradients are enabled.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="deep_nilmtk.preprocessing.html" class="btn btn-neutral float-right" title="Preprocessing package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="deep_nilmtk.loader.html" class="btn btn-neutral float-left" title="Loader package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Boubsiat Hafsa.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>