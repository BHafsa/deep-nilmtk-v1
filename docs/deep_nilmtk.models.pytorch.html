<!DOCTYPE html>
<html class="writer-html5" lang="Python" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>deep_nilmtk.models.pytorch package &mdash; deep-nilmtk 0.0.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="deep_nilmtk.models.tensorflow package" href="deep_nilmtk.models.tensorflow.html" />
    <link rel="prev" title="deep_nilmtk.models package" href="deep_nilmtk.models.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> deep-nilmtk
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">deep_nilmtk</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="deep_nilmtk.html">deep_nilmtk package</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="deep_nilmtk.config.html">deep_nilmtk.config package</a></li>
<li class="toctree-l3"><a class="reference internal" href="deep_nilmtk.data.html">deep_nilmtk.data package</a></li>
<li class="toctree-l3"><a class="reference internal" href="deep_nilmtk.disaggregator.html">deep_nilmtk.disaggregator package</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="deep_nilmtk.models.html">deep_nilmtk.models package</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="deep_nilmtk.models.html#subpackages">Subpackages</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="deep_nilmtk.trainers.html">deep_nilmtk.trainers package</a></li>
<li class="toctree-l3"><a class="reference internal" href="deep_nilmtk.utils.html">deep_nilmtk.utils package</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">deep-nilmtk</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="modules.html">deep_nilmtk</a> &raquo;</li>
          <li><a href="deep_nilmtk.html">deep_nilmtk package</a> &raquo;</li>
          <li><a href="deep_nilmtk.models.html">deep_nilmtk.models package</a> &raquo;</li>
      <li>deep_nilmtk.models.pytorch package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/deep_nilmtk.models.pytorch.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="deep-nilmtk-models-pytorch-package">
<h1>deep_nilmtk.models.pytorch package<a class="headerlink" href="#deep-nilmtk-models-pytorch-package" title="Permalink to this heading"></a></h1>
<section id="module-deep_nilmtk.models.pytorch.seq2point">
<span id="deep-nilmtk-models-pytorch-seq2point-module"></span><h2>deep_nilmtk.models.pytorch.seq2point module<a class="headerlink" href="#module-deep_nilmtk.models.pytorch.seq2point" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.RNN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.seq2point.</span></span><span class="sig-name descname"><span class="pre">RNN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.RNN" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#deep_nilmtk.models.pytorch.seq2point.S2P" title="deep_nilmtk.models.pytorch.seq2point.S2P"><code class="xref py py-class docutils literal notranslate"><span class="pre">S2P</span></code></a></p>
<p>PyTorch implementation of the RNN
NILM model as porposed in :
<a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3360322.3360844">https://dl.acm.org/doi/pdf/10.1145/3360322.3360844</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>params</strong> (<em>dict</em>) -- dictionnary of values relative to hyper-parameters.</p>
</dd>
</dl>
<p>Besides the additional paramter from teh parent model, the params dictionnay is expected to include the following keys:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_type</strong> (<em>int</em>) -- The number of input features, defaults to 1.</p></li>
<li><p><strong>appliances</strong> (<em>list of str</em>) -- A list of appliances.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.RNN.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.RNN.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.RNN.get_template">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_template</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.RNN.get_template" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.RNN.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.RNN.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.S2P">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.seq2point.</span></span><span class="sig-name descname"><span class="pre">S2P</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.S2P" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>This class is an abstract class  for Sequence to point models. By implementing this class,
you can avoid to implement the predict and the forward functions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>params</strong> (<em>dict</em>) -- dictionnary of values relative to hyper-parameters.</p>
</dd>
</dl>
<p>The dictionnay is expected to include the following keys:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_norm</strong> (<em>str.</em>) -- the type of normlization of the target power, defaults to 'z-norm'.</p></li>
<li><p><strong>mean</strong> (<em>float.</em>) -- The mean consumption value of the target appliance, defaults to 0.</p></li>
<li><p><strong>std</strong> (<em>float.</em>) -- The std consumption value  the target power, defaults to 1</p></li>
<li><p><strong>min</strong> (<em>float.</em>) -- The mininum consumption value of the target appliance, defaults to 0.</p></li>
<li><p><strong>max</strong> (<em>float.</em>) -- The maximum consumption value  the target power, defaults to 1</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.S2P.get_template">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_template</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.S2P.get_template" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.S2P.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.S2P.predict" title="Permalink to this definition"></a></dt>
<dd><p>Generate prediction during testing for the test_dataLoader</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> -- pre-trained model.</p></li>
<li><p><strong>test_dataloader</strong> (<em>dataLoader</em>) -- data loader for the testing period.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Disaggregated power consumption.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.S2P.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.S2P.step" title="Permalink to this definition"></a></dt>
<dd><p>Disaggregates a batch of data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>Tensor</em>) -- A batch of data</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss function as returned form the model and the MAE as returned from the model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple(float, float)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.S2P.suggest_hparams">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">suggest_hparams</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trial</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.S2P.suggest_hparams" title="Permalink to this definition"></a></dt>
<dd><p>Function returning list of params that will be suggested from optuna</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>trial</strong> (<em>optuna.trial</em>) -- Optuna Trial.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Parameters with values suggested by optuna</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.S2P.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.S2P.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.SAED">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.seq2point.</span></span><span class="sig-name descname"><span class="pre">SAED</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.SAED" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#deep_nilmtk.models.pytorch.seq2point.S2P" title="deep_nilmtk.models.pytorch.seq2point.S2P"><code class="xref py py-class docutils literal notranslate"><span class="pre">S2P</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.SAED.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.SAED.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.SAED.get_template">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_template</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.SAED.get_template" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.SAED.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.SAED.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.Seq2Point">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.seq2point.</span></span><span class="sig-name descname"><span class="pre">Seq2Point</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.Seq2Point" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#deep_nilmtk.models.pytorch.seq2point.S2P" title="deep_nilmtk.models.pytorch.seq2point.S2P"><code class="xref py py-class docutils literal notranslate"><span class="pre">S2P</span></code></a></p>
<p id="seqpoint">PyTorch implementation of the Seq-to-point
NILM model as porposed in :
<a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3360322.3360844">https://dl.acm.org/doi/pdf/10.1145/3360322.3360844</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>params</strong> (<em>dict</em>) -- dictionnary of values relative to hyper-parameters.</p>
</dd>
</dl>
<p>Besides the additional paramter from teh parent model, the params dictionnay is expected to include the following keys:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_type</strong> (<em>int</em>) -- The number of input features, defaults to 1.</p></li>
<li><p><strong>appliances</strong> (<em>list of str</em>) -- A list of appliances.</p></li>
<li><p><strong>pool_filter</strong> (<em>int</em>) -- The size of pooling filter, defaults to 50.</p></li>
<li><p><strong>latent_size</strong> (<em>int</em>) -- The number of nodes in the last layer, defaults to 1024.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.Seq2Point.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.Seq2Point.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.Seq2Point.get_template">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_template</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.Seq2Point.get_template" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.Seq2Point.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.Seq2Point.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.WindowGRU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.seq2point.</span></span><span class="sig-name descname"><span class="pre">WindowGRU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.WindowGRU" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#deep_nilmtk.models.pytorch.seq2point.S2P" title="deep_nilmtk.models.pytorch.seq2point.S2P"><code class="xref py py-class docutils literal notranslate"><span class="pre">S2P</span></code></a></p>
<p>PyTorch implementation of the Window-GRU
NILM model as porposed in :
<a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3360322.3360844">https://dl.acm.org/doi/pdf/10.1145/3360322.3360844</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>params</strong> (<em>dict</em>) -- dictionnary of values relative to hyper-parameters.</p>
</dd>
</dl>
<p>Besides the additional paramter from teh parent model, the params dictionnay is expected to include the following keys:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_type</strong> (<em>int</em>) -- The number of input features, defaults to 1.</p></li>
<li><p><strong>appliances</strong> (<em>list of str</em>) -- A list of appliances.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.WindowGRU.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.WindowGRU.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.WindowGRU.get_template">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_template</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.WindowGRU.get_template" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2point.WindowGRU.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2point.WindowGRU.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-deep_nilmtk.models.pytorch.seq2seq">
<span id="deep-nilmtk-models-pytorch-seq2seq-module"></span><h2>deep_nilmtk.models.pytorch.seq2seq module<a class="headerlink" href="#module-deep_nilmtk.models.pytorch.seq2seq" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2seq.DAE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.seq2seq.</span></span><span class="sig-name descname"><span class="pre">DAE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2seq.DAE" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#deep_nilmtk.models.pytorch.seq2seq.S2S" title="deep_nilmtk.models.pytorch.seq2seq.S2S"><code class="xref py py-class docutils literal notranslate"><span class="pre">S2S</span></code></a></p>
<p>PyTorch implementation of the DAE
NILM model as porposed in :
<a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3360322.3360844">https://dl.acm.org/doi/pdf/10.1145/3360322.3360844</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>params</strong> (<em>dict</em>) -- dictionnary of values relative to hyper-parameters.</p>
</dd>
</dl>
<p>Besides the additional paramter from teh parent model, the params dictionnay is expected to include the following keys:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_type</strong> (<em>int</em>) -- The number of input features, defaults to 1.</p></li>
<li><p><strong>appliances</strong> (<em>list of str</em>) -- A list of appliances.</p></li>
<li><p><strong>pool_filter</strong> (<em>int</em>) -- The size of pooling filter, defaults to 50.</p></li>
<li><p><strong>latent_size</strong> (<em>int</em>) -- The number of nodes in the last layer, defaults to 1024.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2seq.DAE.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2seq.DAE.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2seq.DAE.get_template">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_template</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2seq.DAE.get_template" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2seq.DAE.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2seq.DAE.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2seq.S2S">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.seq2seq.</span></span><span class="sig-name descname"><span class="pre">S2S</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2seq.S2S" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>This class is an abstract class  for Sequence to Sequence models. By implementing this class,
you can avoid to implement the predict and the forward functions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>params</strong> (<em>dict</em>) -- dictionnary of values relative to hyper-parameters.</p>
</dd>
</dl>
<p>The dictionnay is expected to include the following keys:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_norm</strong> (<em>str.</em>) -- the type of normlization of the target power, defaults to 'z-norm'.</p></li>
<li><p><strong>mean</strong> (<em>float.</em>) -- The mean consumption value of the target appliance, defaults to 0.</p></li>
<li><p><strong>std</strong> (<em>float.</em>) -- The std consumption value  the target power, defaults to 1</p></li>
<li><p><strong>min</strong> (<em>float.</em>) -- The mininum consumption value of the target appliance, defaults to 0.</p></li>
<li><p><strong>max</strong> (<em>float.</em>) -- The maximum consumption value  the target power, defaults to 1</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2seq.S2S.get_template">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_template</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2seq.S2S.get_template" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2seq.S2S.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2seq.S2S.predict" title="Permalink to this definition"></a></dt>
<dd><p>Generate prediction during testing for the test_dataLoader</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> -- pre-trained model.</p></li>
<li><p><strong>test_dataloader</strong> -- data loader for the testing period.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>data loader for the testing period.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2seq.S2S.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2seq.S2S.step" title="Permalink to this definition"></a></dt>
<dd><p>Disaggregates a batch of data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>Tensor</em>) -- A batch of data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss function as returned form the model and MAE as returned from the model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple(float,float)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2seq.S2S.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2seq.S2S.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2seq.Seq2Seq">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.seq2seq.</span></span><span class="sig-name descname"><span class="pre">Seq2Seq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2seq.Seq2Seq" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#deep_nilmtk.models.pytorch.seq2seq.S2S" title="deep_nilmtk.models.pytorch.seq2seq.S2S"><code class="xref py py-class docutils literal notranslate"><span class="pre">S2S</span></code></a></p>
<p id="seqseq">PyTorch implementation of the Window-GRU
NILM model as porposed in :
<a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3360322.3360844">https://dl.acm.org/doi/pdf/10.1145/3360322.3360844</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>params</strong> (<em>dict</em>) -- dictionnary of values relative to hyper-parameters.</p>
</dd>
</dl>
<p>Besides the additional paramter from teh parent model, the params dictionnay is expected to include the following keys:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_type</strong> (<em>int</em>) -- The number of input features, defaults to 1.</p></li>
<li><p><strong>appliances</strong> (<em>list of str</em>) -- A list of appliances.</p></li>
<li><p><strong>pool_filter</strong> (<em>int</em>) -- The size of pooling filter, defaults to 50.</p></li>
<li><p><strong>latent_size</strong> (<em>int</em>) -- The number of nodes in the last layer, defaults to 1024.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2seq.Seq2Seq.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2seq.Seq2Seq.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2seq.Seq2Seq.get_template">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_template</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2seq.Seq2Seq.get_template" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.seq2seq.Seq2Seq.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.seq2seq.Seq2Seq.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-deep_nilmtk.models.pytorch.bert4nilm">
<span id="deep-nilmtk-models-pytorch-bert4nilm-module"></span><h2>deep_nilmtk.models.pytorch.bert4nilm module<a class="headerlink" href="#module-deep_nilmtk.models.pytorch.bert4nilm" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.Attention">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">Attention</span></span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.Attention" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.Attention.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.Attention.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.Attention.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.Attention.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">BERT4NILM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>BERT4NILM implementation.
Original paper can be found here: <a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3427771.3429390">https://dl.acm.org/doi/pdf/10.1145/3427771.3429390</a>
Original code can be found here: <a class="reference external" href="https://github.com/Yueeeeeeee/BERT4NILM">https://github.com/Yueeeeeeee/BERT4NILM</a>
The hyperparameter dictionnary is expected to include the following parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>threshold</strong> (<em>List of floats</em>) -- The threshold for states generation in the target power consumption, defaults to None</p></li>
<li><p><strong>cutoff</strong> (<em>List of floats</em>) -- The cutoff for states generation in the target power consumption, defaults to None</p></li>
<li><p><strong>min_on</strong> (<em>List of floats</em>) -- The min on duration for states generation in the target power consumption, defaults to None</p></li>
<li><p><strong>min_off</strong> (<em>List of floats</em>) -- The min off duration for states generation in the target power consumption, defaults to None</p></li>
<li><p><strong>in_size</strong> (<em>int</em>) -- The length of the input sequence, defaults to 488.</p></li>
<li><p><strong>stride</strong> (<em>int</em>) -- The distance between two consecutive sequences, defaults to 1.</p></li>
<li><p><strong>hidden</strong> (<em>int</em>) -- The hidden size, defaults to 256</p></li>
<li><p><strong>heads</strong> (<em>int</em>) -- The number of attention heads in each transformer block, defaults to 2</p></li>
<li><p><strong>n_layers</strong> (<em>int</em>) -- the number of transformer blocks in the model, defaults to 2</p></li>
</ul>
</dd>
<dt class="field-even">Params dropout</dt>
<dd class="field-even"><p>The dropout, defaults to 0.2</p>
</dd>
</dl>
<p>it can be used as follow:
.. code-block:: python</p>
<blockquote>
<div><dl>
<dt>'Bert4NILM': NILMExperiment({</dt><dd><blockquote>
<div><p>&quot;model_name&quot;: 'BERT4NILM',
'in_size': 480,
'feature_type':'main',
'stride':10,
'max_nb_epochs':1,
'cutoff':{</p>
<blockquote>
<div><p>'aggregate': 6000,
'kettle': 3100,
'fridge': 300,
'washing machine': 2500,
'microwave': 3000,
'dishwasher': 2500</p>
</div></blockquote>
<p>},
'threshold':{</p>
<blockquote>
<div><p>'kettle': 2000,
'fridge': 50,
'washing machine': 20,
'microwave': 200,
'dishwasher': 10</p>
</div></blockquote>
<p>},
'min_on':{</p>
<blockquote>
<div><p>'kettle': 2,
'fridge': 10,
'washing machine': 300,
'microwave': 2,
'dishwasher': 300</p>
</div></blockquote>
<p>},
'min_off':{</p>
<blockquote>
<div><p>'kettle': 0,
'fridge': 2,
'washing machine': 26,
'microwave': 5,
'dishwasher': 300</p>
</div></blockquote>
<p>},</p>
</div></blockquote>
<p>})</p>
</dd>
</dl>
</div></blockquote>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM.compute_status">
<span class="sig-name descname"><span class="pre">compute_status</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM.compute_status" title="Permalink to this definition"></a></dt>
<dd><p>Calculates teh states for the  target data based on the threshold
:param data: The target data
:type data: tensor
:return: The operational states
:rtype: tensor</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM.cutoff_energy">
<span class="sig-name descname"><span class="pre">cutoff_energy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM.cutoff_energy" title="Permalink to this definition"></a></dt>
<dd><p>Removes the spikes from the data
:param data: Power consumption
:type data: tesnor
:return: Updated ower consumption
:rtype: tensor</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sequence</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM.get_template">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_template</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM.get_template" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM.predict" title="Permalink to this definition"></a></dt>
<dd><p>Generates predictions for the test data loader
:param model: Pre-trained model
:type model: nn.Module
:param test_dataloader: The test data
:type test_dataloader: dataLoader
:return: Generated predictions
:rtype: dict</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM.set_hpramas">
<span class="sig-name descname"><span class="pre">set_hpramas</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cutoff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_on</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_off</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM.set_hpramas" title="Permalink to this definition"></a></dt>
<dd><p>Setter for the hyper-parameters related to appliance state generation
:param cutoff: The power cutoff
:type cutoff: float
:param threshold: Threshold of target power consumption
:type threshold: float
:param min_on: Minimum on duration
:type min_on: float
:param min_off: Minimum off duration
:type min_off: float</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seq_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM.step" title="Permalink to this definition"></a></dt>
<dd><p>Disaggregates a batch of data
:param batch: A batch of data.
:type batch: Tensor
:return: loss function as returned form the model and MAE as returned from the model.
:rtype: tuple(float,float)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.BERT4NILM.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.GELU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">GELU</span></span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.GELU" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.GELU.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.GELU.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.GELU.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.GELU.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.LayerNorm">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">LayerNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.LayerNorm" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.LayerNorm.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.LayerNorm.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.LayerNorm.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.LayerNorm.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.MultiHeadedAttention">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">MultiHeadedAttention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.MultiHeadedAttention" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.MultiHeadedAttention.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.MultiHeadedAttention.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.MultiHeadedAttention.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.MultiHeadedAttention.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.PositionalEmbedding">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">PositionalEmbedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.PositionalEmbedding" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.PositionalEmbedding.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.PositionalEmbedding.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.PositionalEmbedding.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.PositionalEmbedding.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.PositionwiseFeedForward">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">PositionwiseFeedForward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_ff</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.PositionwiseFeedForward" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.PositionwiseFeedForward.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.PositionwiseFeedForward.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.PositionwiseFeedForward.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.PositionwiseFeedForward.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.SublayerConnection">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">SublayerConnection</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.SublayerConnection" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.SublayerConnection.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sublayer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.SublayerConnection.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.SublayerConnection.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.SublayerConnection.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.TransformerBlock">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.bert4nilm.</span></span><span class="sig-name descname"><span class="pre">TransformerBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feed_forward_hidden</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.TransformerBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.TransformerBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.TransformerBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.bert4nilm.TransformerBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.bert4nilm.TransformerBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-deep_nilmtk.models.pytorch.temporal_pooling">
<span id="deep-nilmtk-models-pytorch-temporal-pooling-module"></span><h2>deep_nilmtk.models.pytorch.temporal_pooling module<a class="headerlink" href="#module-deep_nilmtk.models.pytorch.temporal_pooling" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.temporal_pooling.Decoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.temporal_pooling.</span></span><span class="sig-name descname"><span class="pre">Decoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.temporal_pooling.Decoder" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Decoder block of the Temporal_pooling layer</p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.temporal_pooling.Decoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.temporal_pooling.Decoder.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.temporal_pooling.Decoder.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.temporal_pooling.Decoder.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.temporal_pooling.Encoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.temporal_pooling.</span></span><span class="sig-name descname"><span class="pre">Encoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.temporal_pooling.Encoder" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Decoder block of the Temporal_pooling layer</p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.temporal_pooling.Encoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.temporal_pooling.Encoder.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.temporal_pooling.Encoder.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.temporal_pooling.Encoder.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.temporal_pooling.PTPNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.temporal_pooling.</span></span><span class="sig-name descname"><span class="pre">PTPNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.temporal_pooling.PTPNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Source: <a class="reference external" href="https://github.com/lmssdd/TPNILM">https://github.com/lmssdd/TPNILM</a>
Check the paper
Non-Intrusive Load Disaggregation by Convolutional
Neural Network and Multilabel Classification
by Luca Massidda, Marino Marrocu and Simone Manca
The hyperparameter dictionnary is expected to include the following parameters
The hyperparameter dictionnary is expected to include the following parameters
:param in_size: The input sequence length, defaults to 99
:type in_size: int
:param border: The delay between the input and out sequence, defaults to 30.
:type border: int
:param appliances: List of appliances
:type appliances: list
:param feature_type: The type of input features generated during pre-processing, defaults to 'main'.
:type feature_type: str
:param init_features: The number of features in the first encoder layer, defaults to 32.
:type init_fetaure: int
:param dropout: Dropout
:type dropout: float
:param target_norm: The type of normalization of the target data, defeaults to 'z-norm'.
:type target_norm: str
:param mean: The mean consumption of the target power, defaults to 0
:type mean: float
:param std: The STD consumption of the target power, defaults to 1
:type std: float
It can be used as follows:
.. code-block::python</p>
<blockquote>
<div><dl class="simple">
<dt>'tempPool': NILMExperiment({</dt><dd><p>&quot;model_name&quot;: 'tempPool',
'experiment_label':'regression',
'in_size': 480,
'input_norm':'z-norm',
'target_norm':'z-norm',
'feature_type':'mains',
'max_nb_epochs':max_nb_epochs,
'task_type':'regression',
'hidden_dim':64,
}),</p>
</dd>
</dl>
</div></blockquote>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.temporal_pooling.PTPNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.temporal_pooling.PTPNet.forward" title="Permalink to this definition"></a></dt>
<dd><p>The step function of the model.
:param x: A batch of the input features.
:return: the power estimation, and the state estimation.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.temporal_pooling.PTPNet.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.temporal_pooling.PTPNet.predict" title="Permalink to this definition"></a></dt>
<dd><p>Generates predictions for the test data loader
:param model: Pre-trained model
:type model: nn.Module
:param test_dataloader: The test data
:type test_dataloader: dataLoader
:return: Generated predictions
:rtype: dict</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.temporal_pooling.PTPNet.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequence_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.temporal_pooling.PTPNet.step" title="Permalink to this definition"></a></dt>
<dd><p>Disaggregates a batch of data
:param batch: A batch of data.
:type batch: Tensor
:return: loss function as returned form the model and MAE as returned from the model.
:rtype: tuple(float,float)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.temporal_pooling.PTPNet.suggest_hparams">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">suggest_hparams</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trial</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.temporal_pooling.PTPNet.suggest_hparams" title="Permalink to this definition"></a></dt>
<dd><p>Function returning list of params that will be suggested from optuna
:param trial: Optuna Trial.
:type trial: optuna.trial
:return: Parameters with values suggested by optuna
:rtype: dict</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.temporal_pooling.PTPNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.temporal_pooling.PTPNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.temporal_pooling.TemporalPooling">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.temporal_pooling.</span></span><span class="sig-name descname"><span class="pre">TemporalPooling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.temporal_pooling.TemporalPooling" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Temporal Pooling mechanism that combines data with different scales.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.temporal_pooling.TemporalPooling.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.temporal_pooling.TemporalPooling.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.temporal_pooling.TemporalPooling.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.temporal_pooling.TemporalPooling.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-deep_nilmtk.models.pytorch.unet_nilm">
<span id="deep-nilmtk-models-pytorch-unet-nilm-module"></span><h2>deep_nilmtk.models.pytorch.unet_nilm module<a class="headerlink" href="#module-deep_nilmtk.models.pytorch.unet_nilm" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.unet_nilm.UNETNILM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.unet_nilm.</span></span><span class="sig-name descname"><span class="pre">UNETNILM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.unet_nilm.UNETNILM" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p id="unet">UNET-NILM implementation
The original paper can be found here: <a class="reference external" href="https://dl.acm.org/doi/abs/10.1145/3427771.3427859">https://dl.acm.org/doi/abs/10.1145/3427771.3427859</a>
The hyperparameter dictionary is expected to include the following parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>appliances</strong> (<em>list</em>) -- List of appliances, defaults to 1</p></li>
<li><p><strong>feature_type</strong> (<em>str</em>) -- The type of input features generated in the pre-processing, defaults  to 'main'</p></li>
<li><p><strong>n_channels</strong> (<em>int</em>) -- the number of output channels, defaults to 1</p></li>
<li><p><strong>pool_filter</strong> (<em>int</em>) -- Pooling filter, defaults to 8</p></li>
<li><p><strong>latent_size</strong> (<em>int</em>) -- The latent size, defaults to 1024</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.unet_nilm.UNETNILM.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.unet_nilm.UNETNILM.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.unet_nilm.UNETNILM.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.unet_nilm.UNETNILM.predict" title="Permalink to this definition"></a></dt>
<dd><p>Generate prediction during testing for the test_dataLoader
:param model: pre-trained model.
:param test_dataloader: data loader for the testing period.
:type test_dataloader: dataLoader
:return: Disaggregated power consumption.
:rtype: tensor</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.unet_nilm.UNETNILM.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.unet_nilm.UNETNILM.step" title="Permalink to this definition"></a></dt>
<dd><p>Disaggregates a batch of data
:param batch: A batch of data.
:type batch: Tensor
:return: loss function as returned form the model and MAE as returned from the model.
:rtype: tuple(float,float)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.unet_nilm.UNETNILM.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.unet_nilm.UNETNILM.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.unet_nilm.UNETNILMSeq2Quantile">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deep_nilmtk.models.pytorch.unet_nilm.</span></span><span class="sig-name descname"><span class="pre">UNETNILMSeq2Quantile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.unet_nilm.UNETNILMSeq2Quantile" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>UNET-NILM impelementation with quantile regression
The orginal paper can be found here: <a class="reference external" href="https://dl.acm.org/doi/abs/10.1145/3427771.3427859">https://dl.acm.org/doi/abs/10.1145/3427771.3427859</a>
The hyperparameter dictionnary is expected to include the following parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>appliances</strong> (<em>list</em>) -- List of appliances, defaults to 1</p></li>
<li><p><strong>feature_type</strong> (<em>str</em>) -- The type of input features generated in the pre-processing, defaults  to 'main'</p></li>
<li><p><strong>n_channels</strong> (<em>int</em>) -- the number of output channels, defaults to 1</p></li>
<li><p><strong>pool_filter</strong> (<em>int</em>) -- Pooling filter, defaults to 8</p></li>
<li><p><strong>latent_size</strong> (<em>int</em>) -- The latent size, defaults to 1024</p></li>
<li><p><strong>quantile</strong> -- The quantiles to use during prediction, defaults to [0.1, 0.25, 0.5, 0.75, 0.9]</p></li>
<li><p><strong>quantile</strong> -- list</p></li>
</ul>
</dd>
</dl>
<p>It can be used as follows:
.. code-block:: python</p>
<blockquote>
<div><dl class="simple">
<dt>'UNETNiLMSeq2Q':NILMExperiment({</dt><dd><p>'model_name': 'UNETNiLMSeq2Quantile',
'in_size': 480,
'feature_type':'mains',
'input_norm':'z-norm',
'target_norm':'z-norm',
'kfolds':3,
'seq_type':'seq2quantile',
'max_nb_epochs':1 }),</p>
</dd>
</dl>
</div></blockquote>
<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.unet_nilm.UNETNILMSeq2Quantile.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.unet_nilm.UNETNILMSeq2Quantile.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.unet_nilm.UNETNILMSeq2Quantile.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.unet_nilm.UNETNILMSeq2Quantile.predict" title="Permalink to this definition"></a></dt>
<dd><p>Generate prediction during testing for the test_dataLoader
:param model: pre-trained model.
:param test_dataloader: data loader for the testing period.
:type test_dataloader: dataLoader
:return: Disaggregated power consumption.
:rtype: tensor</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.unet_nilm.UNETNILMSeq2Quantile.smooth_pinball_loss">
<span class="sig-name descname"><span class="pre">smooth_pinball_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kappa</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.unet_nilm.UNETNILMSeq2Quantile.smooth_pinball_loss" title="Permalink to this definition"></a></dt>
<dd><p>The implementation of the Pinball loss for NILM, original code can be found in :
<a class="reference external" href="https://github.com/hatalis/smooth-pinball-neural-network/blob/master/pinball_loss.py">https://github.com/hatalis/smooth-pinball-neural-network/blob/master/pinball_loss.py</a>
Hatalis, Kostas, et al. &quot;A Novel Smoothed Loss and Penalty Function
for Noncrossing Composite Quantile Estimation via Deep Neural Networks.&quot; arXiv preprint (2019).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.unet_nilm.UNETNILMSeq2Quantile.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deep_nilmtk.models.pytorch.unet_nilm.UNETNILMSeq2Quantile.step" title="Permalink to this definition"></a></dt>
<dd><p>Disaggregates a batch of data
:param batch: A batch of data.
:type batch: Tensor
:return: loss function as returned form the model and MAE as returned from the model.
:rtype: tuple(float,float)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="deep_nilmtk.models.pytorch.unet_nilm.UNETNILMSeq2Quantile.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#deep_nilmtk.models.pytorch.unet_nilm.UNETNILMSeq2Quantile.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="deep_nilmtk.models.html" class="btn btn-neutral float-left" title="deep_nilmtk.models package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="deep_nilmtk.models.tensorflow.html" class="btn btn-neutral float-right" title="deep_nilmtk.models.tensorflow package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Bousbiat Hafsa.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>